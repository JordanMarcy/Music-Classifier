import util, random, math, sys
from math import exp, log
from util import Counter

############################################################
# Feature extractors: a feature extractor should take a raw input x (tuple of
# tokens) and add features to the featureVector (Counter) provided.

def basicFeatureExtractor(x):
  url, title = x
  featureVector = util.Counter()

  # For each token in the URL, add an indicator feature
  for token in url.split("/"):
    featureVector['url:' + token] += 1

  return featureVector

def customFeatureExtractor(x):
  url, title = x
  featureVector = util.Counter()
  "*** YOUR CODE HERE (around 25 lines of code expected) ***"
  for token in url.split("/"):
    featureVector['url:' + token] += 1
#    for newtoken in token.split('.'):
#      featureVector['url:' + newtoken] += 1
  for token in title.split(" "):
    featureVector['title:' + token] += 1

#  titleFeatures = util.Counter()
#  for token in title.split(" "):
#    titleFeatures[token] += 1
#  for feature1, count1 in titleFeatures.items():
#    for feature2, count2 in titleFeatures.items():
#      featureVector['title:'+feature1+'*'+feature2] += 1
  #oldFeatureVector = featureVector.copy()
  #for feature1, count1 in oldFeatureVector.items():
   # for feature2, count2 in oldFeatureVector.items():
    #  featureVector[feature1+'*'+feature2] = count1*count2 

  return featureVector

############################################################
# You should implement the logistic, hinge, and squared loss.
# Each function takes a featureVector phi(x), output, y, weights, w and returns
# either the value of the loss at that point or the gradient of the loss at
# that point.

"""
The logistic loss, for a given weight vector.
@param featureVector: The featurized representation of a training example
@param y: The true value of the example (in our case, +/- 3)
@param weights: The weight vector assigning a weight to every feature
@return The scalar value of the logistic loss.
"""
def logisticLoss(featureVector, y, weights):
  prediction = featureVector * weights
  return log(1+exp(-prediction*y))
"""
The gradient of the logistic loss with respect to the weight vector.
@param featureVector: The featurized representation of a training example
@param y: The true value of the example (in our case, +/- 1)
@param weights: The weight vector assigning a weight to every feature
@return The gradient [vector] of the logistic loss, with respect to w,
        the weights we are learning.
"""
def logisticLossGradient(featureVector, y, weights):
  "*** YOUR CODE HERE (around 3 lines of code expected) ***"
  gradient = util.Counter()
  prediction = featureVector*weights
  for feature, count in featureVector.items(): 
    gradient[feature] = -(1-1.0/(1+exp(-prediction*y)))*count*y
  return gradient
  

"""
The hinge loss, for a given weight vector.
@param featureVector: The featurized representation of a training example
@param y: The true value of the example (in our case, +/- 1)
@param weights: The weight vector assigning a weight to every feature
@return The scalar value of the hinge loss.
"""
def hingeLoss(featureVector, y, weights):
  "*** YOUR CODE HERE (around 2 lines of code expected) ***"
  prediction = featureVector * weights
  return max(1-prediction*y,0)

"""
The gradient of the hinge loss with respect to the weight vector.
@param featureVector: The featurized representation of a training example
@param y: The true value of the example (in our case, +/- 1)
@param weights: The weight vector assigning a weight to every feature
@return The gradient [vector] of the hinge loss, with respect to w,
        the weights we are learning.
        You should not worry about the case when the hinge loss is exactly 1
"""
def hingeLossGradient(featureVector, y, weights):
  "*** YOUR CODE HERE (around 3 lines of code expected) ***"
  gradient = util.Counter()
  if max(1-featureVector*weights*y,0) != 0:
    for feature, count in featureVector.items(): gradient[feature] = -count*y
  return gradient


"""
The squared loss, for a given weight vector.
@param featureVector: The featurized representation of a training example
@param y: The true value of the example (in our case, +/- 1)
@param weights: The weight vector assigning a weight to every feature
@return The scalar value of the squared loss.
"""
def squaredLoss(featureVector, y, weights):
  "*** YOUR CODE HERE (around 2 lines of code expected) ***"
  prediction = featureVector * weights
  return .5*(prediction-y)**2

"""
The gradient of the squared loss with respect to the weight vector.
@param featureVector: The featurized representation of a training example
@param y: The true value of the example (in our case, +/- 1)
@param weights: The weight vector assigning a weight to every feature
@return The gradient [vector] of the squared loss, with respect to w,
        the weights we are learning.
"""

def squaredLossGradient(featureVector, y, weights):
  "*** YOUR CODE HERE (around 2 lines of code expected) ***"
  gradient = util.Counter()
  for feature, count in featureVector.items(): 
    gradient[feature] = (weights*featureVector-y)*count
  return gradient


class StochasticGradientLearner():
  def __init__(self, featureExtractor):
    self.featureExtractor = util.memoizeById(featureExtractor)

  """
  This function takes a list of training examples and performs stochastic 
  gradient descent to learn weights.
  @param trainExamples: list of training examples (you should only use this to
                        update weights).
                        Each element of this list is a list whose first element
                        is the input, and the second element, and the second
                        element is the true label of the training example.
  @param validationExamples: list of validation examples (just to see how well
                             you're generalizing)
  @param loss: function that takes (x, y, weights) and returns a number
               representing the loss.
  @param lossGradient: function that takes (x, y, weights) and returns the
                       gradient vector as a counter.
                       Recall that this is a function of the featureVector,
                       the true label, and the current weights.
  @param options: various parameters of the algorithm
     * initStepSize: the initial step size
     * stepSizeReduction: the t-th update should have step size:
                          initStepSize / t^stepSizeReduction
     * numRounds: make this many passes over your training data
     * regularization: the 'lambda' term in L2 regularization
  @return No return value, but you should set self.weights to be a counter with
          the new weights, after learning has finished.
  """
  def learn(self, trainExamples, validationExamples, loss, lossGradient, options):
    self.weights = util.Counter()
    random.seed(42)

    # You should go over the training data numRounds times.
    # Each round, go through all the examples in some random order and update
    # the weights with respect to the gradient.
    for round in range(0, options.numRounds):
      random.shuffle(trainExamples)
      numUpdates = 0  # Should be incremented with each example and determines the step size.

      # Loop over the training examples and update the weights based on loss and regularization.
      # If your code runs slowly, try to explicitly write out the dot products
      # in the code here (e.g., "for key,value in counter: counter[key] += ---"
      # rather than "counter * other_vector")
      for x, y in trainExamples:
        numUpdates += 1
        "*** YOUR CODE HERE (around 7 lines of code expected) ***"
        weights = self.weights.copy()
        
        featureVector = self.featureExtractor(x)
        lossGrad = lossGradient(featureVector, y, weights)
        stepsize = 1.0*options.initStepSize/(numUpdates**options.stepSizeReduction)
        regTerm = 1.0*options.regularization / len(trainExamples)
        for feature, count in featureVector.items():
          self.weights[feature] = weights[feature] - stepsize*(lossGrad[feature] + regTerm * weights[feature])

      # Compute the objective function.
      # Here, we have split the objective function into two components:
      # the training loss, and the regularization penalty.
      # The objective function is the sum of these two values
      trainLoss = 0  # Training loss
      regularizationPenalty = 0  # L2 Regularization penalty
      "*** YOUR CODE HERE (around 5 lines of code expected) ***"
      for x, y in trainExamples: 
        trainLoss += loss(self.featureExtractor(x), y, weights)
      for feature, weight in weights.items():
        regularizationPenalty += weight**2
      regularizationPenalty *= 0.5*options.regularization
      self.objective = trainLoss + regularizationPenalty

      # See how well we're doing on our actual goal (error rate).
      trainError = util.getClassificationErrorRate(trainExamples, self.predict, 'train', options.verbose, self.featureExtractor, self.weights)
      validationError = util.getClassificationErrorRate(validationExamples, self.predict, 'validation', options.verbose, self.featureExtractor, self.weights)

      print "Round %s/%s: objective = %.2f = %.2f + %.2f, train error = %.4f, validation error = %.4f" % (round+1, options.numRounds, self.objective, trainLoss, regularizationPenalty, trainError, validationError)

    # Print out feature weights
    out = open('weights', 'w')
    for f, v in sorted(self.weights.items(), key=lambda x: -x[1]):
      print >>out, f + "\t" + str(v)
    out.close()

  """
  Classify a new input into either +1 or -1 based on the current weights
  (self.weights). Note that this function should be agnostic to the loss
  you are using for training.
  You may find the following fields useful:
    self.weights: Your current weights
    self.featureExtractor(): A function which takes a datum as input and
                             returns a featurized version of the datum.
  @param x An input example, not yet featurized.
  @return +1 or -1
  """
  def predict(self, x):
    "*** YOUR CODE HERE (around 3 lines of code expected) ***"
    featureVector = self.featureExtractor(x)
    prediction = self.weights*featureVector
    return -1 if prediction < 0 else 1

# After you have tuned your parameters, set the hyperparameter options:
# featureExtractor, loss, initStepSize, stepSizeReduction, numRounds, regularization, etc.
# The autograder will call this function before calling learn().
def setTunedOptions(options):
  "*** YOUR CODE HERE (around 6 lines of code expected) ***"
#  options.featureExtractor = 'custom'
  options.loss = 'hinge'
  options.initStepSize = 1
  options.stepSizeReduction = .5
  options.numRounds = 9
  options.regularization = 1

if __name__ == '__main__':
  util.runLearner(sys.modules[__name__], sys.argv[1:])
